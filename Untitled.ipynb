{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d214b15d-e8f3-42bc-b690-1aa89db6d705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import pytesseract  # For OCR using Tesseract\n",
    "import time         # For measuring execution time\n",
    "import pdf2image    # For converting PDF pages to images\n",
    "from PIL import Image  # For image processing\n",
    "import requests     # For API calls to Anthropic\n",
    "import difflib      # For text comparison\n",
    "import numpy as np  # For numerical operations\n",
    "import cv2          # For advanced image processing\n",
    "import matplotlib.pyplot as plt  # For visualizations\n",
    "import io           # For handling byte streams\n",
    "import base64       # For encoding/decoding binary data\n",
    "from dotenv import load_dotenv  # For loading environment variables from .env file\n",
    "from tqdm import tqdm  # For progress bars\n",
    "import os           # For interacting with the operating system\n",
    "import logging      # For logging messages\n",
    "import concurrent.futures  # For parallel execution of tasks\n",
    "from requests.adapters import HTTPAdapter  # For configuring HTTP requests\n",
    "from requests.packages.urllib3.util.retry import Retry  # For implementing retry logic in HTTP requests\n",
    "from google.cloud import vision # For the Google Cloud Vision client library\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import Levenshtein  # For efficient edit distance calculations\n",
    "import anthropic\n",
    "import pickle\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional\n",
    "from fuzzywuzzy import fuzz\n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bdd2e261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MAX_WORKERS = os.cpu_count() or 4 # Adjust workers to the number of CPU cores available of current system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a3d13a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Types\n",
    "\n",
    "@dataclass\n",
    "class BoundingBox:\n",
    "    page_number: int\n",
    "    x: float\n",
    "    y: float\n",
    "    width: float\n",
    "    height: float\n",
    "    text: str\n",
    "    confidence: Optional[float] = None\n",
    "    type: Optional[str] = None  # For Mathpix: 'line' or 'word'\n",
    "\n",
    "@dataclass\n",
    "class OCRPageResult:\n",
    "    page_number: int\n",
    "    text: str\n",
    "    bounding_boxes: List[BoundingBox]\n",
    "    processing_time: float\n",
    "    avg_confidence: Optional[float] = None  # For Tesseract\n",
    "\n",
    "@dataclass\n",
    "class OCRResult:\n",
    "    ocr_text: str\n",
    "    page_results: List[OCRPageResult]\n",
    "    total_time: float\n",
    "    ocr_engine: str\n",
    "\n",
    "@dataclass\n",
    "class AnthropicPageResult:\n",
    "    page_number: int\n",
    "    text: str\n",
    "    processing_time: float\n",
    "\n",
    "@dataclass\n",
    "class AnthropicResult:\n",
    "    full_text: str\n",
    "    page_results: List[AnthropicPageResult]\n",
    "    total_time: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d635e36-72fb-4aab-8448-f49334334e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD ENVIRONMENT VARIABLES\n",
    "load_dotenv()\n",
    "\n",
    "# ANTHROPIC\n",
    "ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')\n",
    "if not ANTHROPIC_API_KEY:\n",
    "    raise ValueError(\"Please set the ANTHROPIC_API_KEY environment variable.\")\n",
    "\n",
    "print(f\"Anthropic API Key: {ANTHROPIC_API_KEY[:5]}...{ANTHROPIC_API_KEY[-5:]}\")  # Only print first and last 5 characters\n",
    "\n",
    "# Initialize the Anthropic client at the top of your script\n",
    "client = anthropic.Anthropic()\n",
    "\n",
    "# MATHPIX\n",
    "MATHPIX_APP_ID = os.getenv('MATHPIX_APP_ID')\n",
    "MATHPIX_APP_KEY = os.getenv('MATHPIX_APP_KEY')\n",
    "\n",
    "if not MATHPIX_APP_ID or not MATHPIX_APP_KEY:\n",
    "    raise ValueError(\"Please set the MATHPIX_APP_ID and MATHPIX_APP_KEY environment variables.\")\n",
    "\n",
    "# GOOGLE CLOUD VISION\n",
    "GOOGLE_APPLICATION_CREDENTIALS = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')\n",
    "if not GOOGLE_APPLICATION_CREDENTIALS:\n",
    "    raise ValueError(\"Please set the GOOGLE_APPLICATION_CREDENTIALS environment variable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b077effa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For checkpointing\n",
    "def save_checkpoint(data, filename):\n",
    "       with open(filename, 'wb') as f:\n",
    "           pickle.dump(data, f)\n",
    "\n",
    "def load_checkpoint(filename):\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a8a70f93-383a-4f55-aeaa-64dead1bbc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Setup a session with retry strategy\n",
    "session = requests.Session()\n",
    "retry = Retry(\n",
    "    total=5,\n",
    "    backoff_factor=1,\n",
    "    status_forcelist=[429, 500, 502, 503, 504],\n",
    "    allowed_methods=[\"POST\"]\n",
    ")\n",
    "adapter = HTTPAdapter(max_retries=retry)\n",
    "session.mount(\"https://\", adapter)\n",
    "session.mount(\"http://\", adapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b74002a8-0cef-422d-b4e8-810d134bbcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_base64(image, max_dim=1568):\n",
    "    \"\"\"\n",
    "    Converts a PIL Image to a base64-encoded string after resizing if necessary.\n",
    "\n",
    "    Parameters:\n",
    "    - image (PIL.Image): The image to convert.\n",
    "    - max_dim (int): Maximum dimension (width or height) in pixels.\n",
    "\n",
    "    Returns:\n",
    "    - str: Base64-encoded string of the image.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Resize image if any dimension exceeds max_dim\n",
    "        if max(image.size) > max_dim:\n",
    "            ratio = max_dim / max(image.size)\n",
    "            new_size = (int(image.size[0] * ratio), int(image.size[1] * ratio))\n",
    "            image = image.resize(new_size, Image.LANCZOS)\n",
    "        \n",
    "        buffered = io.BytesIO()\n",
    "        image.save(buffered, format=\"PNG\")  # Use PNG for lossless quality\n",
    "        img_bytes = buffered.getvalue()\n",
    "        img_base64 = base64.b64encode(img_bytes).decode('utf-8')\n",
    "        return img_base64\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in image_to_base64: {e}\", exc_info=True)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ff9dc0db-9686-4538-b6ec-ce471a7b726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    Preprocess the image to enhance OCR accuracy.\n",
    "\n",
    "    Parameters:\n",
    "    - image (PIL.Image): The image to preprocess.\n",
    "\n",
    "    Returns:\n",
    "    - PIL.Image: The preprocessed image.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert to grayscale\n",
    "        image = image.convert('L')\n",
    "        \n",
    "        # Convert to NumPy array for OpenCV processing\n",
    "        image_np = np.array(image)\n",
    "        \n",
    "        # Apply denoising\n",
    "        image_np = cv2.fastNlMeansDenoising(image_np, h=30)\n",
    "\n",
    "        # Apply adaptive thresholding\n",
    "        image_np = cv2.adaptiveThreshold(image_np, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                        cv2.THRESH_BINARY, 11, 2)\n",
    "        \n",
    "        # Detect and correct skew\n",
    "        coords = np.column_stack(np.where(image_np > 0))\n",
    "        angle = cv2.minAreaRect(coords)[-1]\n",
    "        if angle < -45:\n",
    "            angle = -(90 + angle)\n",
    "        else:\n",
    "            angle = -angle\n",
    "        \n",
    "        (h, w) = image_np.shape\n",
    "        center = (w // 2, h // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        rotated = cv2.warpAffine(image_np, M, (w, h), flags=cv2.INTER_CUBIC, \n",
    "                                borderMode=cv2.BORDER_REPLICATE)\n",
    "        \n",
    "        # Convert back to PIL Image\n",
    "        preprocessed_image = Image.fromarray(image_np)\n",
    "        return preprocessed_image\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in preprocess_image: {e}\", exc_info=True)\n",
    "        return image  # Return original image if preprocessing fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "08b04abf-52b0-4ab5-a101-00562d21f24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pdf_to_images(pdf_path, dpi=300):\n",
    "    \"\"\"\n",
    "    Converts a PDF file to a list of PIL Image objects.\n",
    "\n",
    "    Parameters:\n",
    "    - pdf_path (str): Path to the PDF file.\n",
    "    - dpi (int): Resolution for the conversion.\n",
    "\n",
    "    Returns:\n",
    "    - list of PIL.Image: List of images representing each PDF page.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        images = pdf2image.convert_from_path(pdf_path, dpi=dpi)\n",
    "        logger.info(f\"Converted PDF to {len(images)} images.\")\n",
    "        return images\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"PDF file not found: {pdf_path}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to convert PDF to images: {e}\", exc_info=True)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5353dfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base OCR Class\n",
    "\n",
    "class BaseOCR(ABC):\n",
    "    def __init__(self, max_workers=MAX_WORKERS):\n",
    "        self.max_workers = max_workers\n",
    "\n",
    "    @abstractmethod\n",
    "    def process_page(self, page_number, image):\n",
    "        pass\n",
    "\n",
    "    def perform_ocr(self, pdf_path):\n",
    "        images = convert_pdf_to_images(pdf_path)\n",
    "        num_pages = len(images)\n",
    "        logging.info(f\"Total pages to process: {num_pages}\")\n",
    "\n",
    "        if num_pages == 0:\n",
    "            logging.warning(\"No images extracted from PDF.\")\n",
    "            return OCRResult(ocr_text='', page_results=[], total_time=0.0, ocr_engine=self.__class__.__name__)\n",
    "\n",
    "        total_start_time = time.time()\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
    "            futures = {executor.submit(self.process_page, i, img): i for i, img in enumerate(images)}\n",
    "            \n",
    "            page_results = []\n",
    "            for future in tqdm(concurrent.futures.as_completed(futures), total=num_pages, desc=f\"Performing {self.__class__.__name__} OCR\"):\n",
    "                page_number = futures[future]\n",
    "                try:\n",
    "                    page_result = future.result()\n",
    "                    page_results.append(page_result)\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error processing page {page_number + 1}: {e}\", exc_info=True)\n",
    "                    page_results.append(OCRPageResult(page_number=page_number+1, text='', bounding_boxes=[], processing_time=0.0))\n",
    "\n",
    "        total_time = time.time() - total_start_time\n",
    "        logging.info(f\"Total {self.__class__.__name__} OCR time: {total_time:.2f} seconds.\")\n",
    "\n",
    "        ocr_text = '\\n'.join(result.text for result in page_results)\n",
    "        return OCRResult(ocr_text=ocr_text, page_results=page_results, total_time=total_time, ocr_engine=self.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34f4f08a-c3d5-4734-93d6-c33332574212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_page(page_number, image):\n",
    "    \"\"\"\n",
    "    Processes a single PDF page: preprocesses image, sends API request, and retrieves text and processing time.\n",
    "\n",
    "    Parameters:\n",
    "    - page_number (int): The page number.\n",
    "    - image (PIL.Image): The image of the page.\n",
    "\n",
    "    Returns:\n",
    "    - AnthropicPageResult: Extracted text and processing time for the page.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Preprocess image\n",
    "        preprocessed_image = preprocess_image(image)\n",
    "        \n",
    "        # Convert image to base64\n",
    "        image_base64 = image_to_base64(preprocessed_image)\n",
    "        \n",
    "        # Prepare the message content\n",
    "        message_content = [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"source\": {\n",
    "                    \"type\": \"base64\",\n",
    "                    \"media_type\": \"image/png\",\n",
    "                    \"data\": image_base64,\n",
    "                },\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Output all the text in this page.\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Make the API call using the Anthropic client\n",
    "        start_time = time.time()\n",
    "        message = client.messages.create(\n",
    "            model=\"claude-3-5-sonnet-20240620\",\n",
    "            max_tokens=1024,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": message_content,\n",
    "                }\n",
    "            ],\n",
    "        )\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        # Extract the text from the response\n",
    "        text = message.content[0].text if message.content else ''\n",
    "\n",
    "        logging.info(f\"Page {page_number} processed in {elapsed_time:.2f} seconds.\")\n",
    "        return AnthropicPageResult(page_number=page_number, text=text, processing_time=elapsed_time)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing page {page_number}: {e}\", exc_info=True)\n",
    "        return AnthropicPageResult(page_number=page_number, text='', processing_time=0.0)\n",
    "\n",
    "    \n",
    "def get_anthropic_ground_truth(pdf_path, max_workers=5):\n",
    "    \"\"\"\n",
    "    Extracts ground truth text from a PDF using the Anthropic Vision API.\n",
    "\n",
    "    Parameters:\n",
    "    - pdf_path (str): Path to the PDF file.\n",
    "    - max_workers (int): Number of worker processes for parallel processing.\n",
    "\n",
    "    Returns:\n",
    "    - AnthropicResult: Extracted text, per-page results, and total processing time.\n",
    "    \"\"\"\n",
    "    images = convert_pdf_to_images(pdf_path)\n",
    "    \n",
    "    if not images:\n",
    "        logging.warning(\"No images to process.\")\n",
    "        return AnthropicResult(full_text='', page_results=[], total_time=0.0)\n",
    "    \n",
    "    num_pages = len(images)\n",
    "    logging.info(f\"Total pages to process with Anthropic: {num_pages}\")\n",
    "    \n",
    "    # Start total processing timing\n",
    "    start_total = time.time()\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [\n",
    "            executor.submit(process_page, page_number, image)\n",
    "            for page_number, image in enumerate(images, start=1)\n",
    "        ]\n",
    "        page_results = []\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc=\"Processing pages\"):\n",
    "            page_result = future.result()\n",
    "            page_results.append(page_result)\n",
    "    \n",
    "    # Sort page results by page number\n",
    "    page_results.sort(key=lambda x: x.page_number)\n",
    "    \n",
    "    # Concatenate all pages' text\n",
    "    full_text = '\\n'.join(result.text for result in page_results)\n",
    "    \n",
    "    # Calculate total processing time\n",
    "    total_time = time.time() - start_total\n",
    "    logging.info(f\"Total time to obtain ground truth: {total_time:.2f} seconds.\")\n",
    "    \n",
    "    return AnthropicResult(full_text=full_text, page_results=page_results, total_time=total_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4211e2ee-2700-44c0-82e5-4125e9fb24a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper function for OCR processing\n",
    "def ocr_page(page_number, image):\n",
    "    \"\"\"\n",
    "    Performs OCR on a single image and measures processing time.\n",
    "\n",
    "    Parameters:\n",
    "    - page_number (int): The page number.\n",
    "    - image (PIL.Image): The image to perform OCR on.\n",
    "\n",
    "    Returns:\n",
    "    - (text, data, processing_time, avg_confidence): Tuple containing OCR text, data, time taken, and average confidence.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Preprocess image using existing function\n",
    "        preprocessed_image = preprocess_image(image)\n",
    "\n",
    "        # Start timing\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Perform OCR to extract text with configuration\n",
    "        custom_config = r'--oem 3 --psm 6'  # Example configuration\n",
    "        text = pytesseract.image_to_string(preprocessed_image, config=custom_config, lang='eng')\n",
    "\n",
    "        # Perform OCR to extract data with bounding boxes and confidence levels\n",
    "        data = pytesseract.image_to_data(preprocessed_image, output_type=pytesseract.Output.DICT, config=custom_config, lang='eng')\n",
    "\n",
    "        # Extract confidence levels\n",
    "        confidences = data['conf']\n",
    "\n",
    "        # End timing\n",
    "        end_time = time.time()\n",
    "        processing_time = end_time - start_time\n",
    "\n",
    "        logging.info(f\"Page {page_number + 1} processed in {processing_time:.2f} seconds.\")\n",
    "\n",
    "        # Calculate average confidence for this page\n",
    "        valid_confidences = [conf for conf in confidences if conf != -1]  # -1 indicates no confidence available\n",
    "        avg_confidence = sum(valid_confidences) / len(valid_confidences) if valid_confidences else None\n",
    "\n",
    "        if avg_confidence is not None:\n",
    "            logging.info(f\"Page {page_number + 1} average confidence: {avg_confidence:.2f}\")\n",
    "        else:\n",
    "            logging.info(f\"Page {page_number + 1} average confidence: Not available\")\n",
    "\n",
    "        return text, data, processing_time, avg_confidence\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing page {page_number + 1}: {e}\")\n",
    "        return '', {}, 0.0, None\n",
    "\n",
    "def perform_tesseract_ocr(pdf_path, max_workers=MAX_WORKERS):\n",
    "    \"\"\"\n",
    "    Performs OCR on a PDF document using Tesseract and evaluates processing speed.\n",
    "\n",
    "    Parameters:\n",
    "    - pdf_path (str): Path to the PDF file.\n",
    "    - max_workers (int or None): Number of worker processes for parallel OCR.\n",
    "                                 If None, it will default to os.cpu_count().\n",
    "\n",
    "    Returns:\n",
    "    - ocr_text (str): Concatenated OCR text from all pages.\n",
    "    - ocr_data_pages (list): List of OCR data dictionaries with bounding boxes.\n",
    "    - total_time (float): Total time taken for OCR in seconds.\n",
    "    - per_page_times (list): List of processing times per page in seconds.\n",
    "    \"\"\"\n",
    "    ocr_text_pages = []\n",
    "    ocr_data_pages = []\n",
    "    per_page_times = []\n",
    "    per_page_confidences = []\n",
    "\n",
    "    # Convert PDF to images using existing function\n",
    "    images = convert_pdf_to_images(pdf_path)\n",
    "    num_pages = len(images)\n",
    "    logging.info(f\"Total pages to process: {num_pages}\")\n",
    "\n",
    "    if num_pages == 0:\n",
    "        logging.warning(\"No images extracted from PDF.\")\n",
    "        return '', [], 0.0, []\n",
    "\n",
    "    # Start total OCR timing\n",
    "    total_start_time = time.time()\n",
    "\n",
    "    # Use ThreadPoolExecutor for parallel processing\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(ocr_page, i, img): i for i, img in enumerate(images)}\n",
    "\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=num_pages, desc=\"Performing Tesseract OCR\"):\n",
    "            page_number = futures[future]\n",
    "            try:\n",
    "                text, data, proc_time, avg_confidence = future.result()\n",
    "                ocr_text_pages.append(text)\n",
    "                ocr_data_pages.append(data)\n",
    "                per_page_times.append(proc_time)\n",
    "                per_page_confidences.append(avg_confidence)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error retrieving result for page {page_number + 1}: {e}\", exc_info=True)\n",
    "\n",
    "\n",
    "\n",
    "    # End total OCR timing\n",
    "    total_end_time = time.time()\n",
    "    total_time = total_end_time - total_start_time\n",
    "    logging.info(f\"Total OCR time: {total_time:.2f} seconds.\")\n",
    "\n",
    "    # Concatenate all pages' text\n",
    "    ocr_text = '\\n'.join(ocr_text_pages)\n",
    "\n",
    "    page_results = []\n",
    "    for i, (text, data, proc_time, avg_confidence) in enumerate(zip(ocr_text_pages, ocr_data_pages, per_page_times, per_page_confidences)):\n",
    "        bounding_boxes = [\n",
    "            BoundingBox(\n",
    "                page_number=i+1,\n",
    "                x=data['left'][j],\n",
    "                y=data['top'][j],\n",
    "                width=data['width'][j],\n",
    "                height=data['height'][j],\n",
    "                text=data['text'][j],\n",
    "                confidence=data['conf'][j] if data['conf'][j] != -1 else None\n",
    "            )\n",
    "            for j in range(len(data['text']))\n",
    "            if data['text'][j].strip()\n",
    "        ]\n",
    "        page_results.append(OCRPageResult(\n",
    "            page_number=i+1,\n",
    "            text=text,\n",
    "            bounding_boxes=bounding_boxes,\n",
    "            processing_time=proc_time,\n",
    "            avg_confidence=avg_confidence\n",
    "        ))\n",
    "\n",
    "    return OCRResult(\n",
    "        ocr_text=ocr_text,\n",
    "        page_results=page_results,\n",
    "        total_time=total_time,\n",
    "        ocr_engine=\"Tesseract\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "56ecbad6-c771-46f3-a269-23c77d1da4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper function for OCR processing\n",
    "def ocr_page_mathpix(page_number, image):\n",
    "    \"\"\"\n",
    "    Performs OCR on a single image using MathPix and extracts bounding boxes with confidence levels.\n",
    "\n",
    "    Parameters:\n",
    "    - page_number (int): The page number.\n",
    "    - image (PIL.Image): The image to perform OCR on.\n",
    "\n",
    "    Returns:\n",
    "    - (text, bounding_boxes, processing_time): Tuple containing OCR text,\n",
    "      bounding boxes with confidence, and time taken.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Preprocess image using existing function\n",
    "        preprocessed_image = preprocess_image(image)\n",
    "        \n",
    "        # Convert image to base64\n",
    "        image_base64 = image_to_base64(preprocessed_image)\n",
    "        \n",
    "        # Prepare the JSON payload\n",
    "        payload = {\n",
    "            \"src\": f\"data:image/png;base64,{image_base64}\",\n",
    "            \"formats\": [\"text\", \"data\"],\n",
    "            \"data_options\": {\n",
    "                \"include_line_data\": True,\n",
    "                \"include_word_data\": True\n",
    "            },\n",
    "            \"rm_spaces\": True\n",
    "        }\n",
    "        \n",
    "        headers = {\n",
    "            \"app_id\": MATHPIX_APP_ID,\n",
    "            \"app_key\": MATHPIX_APP_KEY,\n",
    "            \"Content-type\": \"application/json\"\n",
    "        }\n",
    "        \n",
    "        api_endpoint = \"https://api.mathpix.com/v3/text\"\n",
    "        \n",
    "        # Start timing\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Send OCR request to MathPix\n",
    "        response = requests.post(api_endpoint, json=payload, headers=headers)\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        response_json = response.json()\n",
    "        text = response_json.get('text', '')\n",
    "        \n",
    "        # Extract bounding boxes from line_data and word_data\n",
    "        bounding_boxes = []\n",
    "        \n",
    "        # Extract Line Bounding Boxes\n",
    "        line_data = response_json.get('line_data', [])\n",
    "        for line in line_data:\n",
    "            if line.get('included', False):\n",
    "                cnt = line.get('cnt', [])\n",
    "                # Calculate bounding box from contour points\n",
    "                if cnt:\n",
    "                    xs = [point[0] for point in cnt]\n",
    "                    ys = [point[1] for point in cnt]\n",
    "                    bbox = {\n",
    "                        \"page_number\": page_number + 1,\n",
    "                        \"type\": \"line\",\n",
    "                        \"x\": min(xs),\n",
    "                        \"y\": min(ys),\n",
    "                        \"width\": max(xs) - min(xs),\n",
    "                        \"height\": max(ys) - min(ys),\n",
    "                        \"text\": line.get('text', ''),\n",
    "                        \"confidence\": line.get('confidence', None),\n",
    "                        \"confidence_rate\": line.get('confidence_rate', None)\n",
    "                    }\n",
    "                    bounding_boxes.append(bbox)\n",
    "        \n",
    "        # Extract Word Bounding Boxes\n",
    "        word_data = response_json.get('word_data', [])\n",
    "        for word in word_data:\n",
    "            if word.get('type') == 'text' and word.get('included', False):\n",
    "                cnt = word.get('cnt', [])\n",
    "                if cnt:\n",
    "                    xs = [point[0] for point in cnt]\n",
    "                    ys = [point[1] for point in cnt]\n",
    "                    bbox = {\n",
    "                        \"page_number\": page_number + 1,\n",
    "                        \"type\": \"word\",\n",
    "                        \"x\": min(xs),\n",
    "                        \"y\": min(ys),\n",
    "                        \"width\": max(xs) - min(xs),\n",
    "                        \"height\": max(ys) - min(ys),\n",
    "                        \"text\": word.get('text', ''),\n",
    "                        \"confidence\": word.get('confidence', None),\n",
    "                        \"confidence_rate\": word.get('confidence_rate', None)\n",
    "                    }\n",
    "                    bounding_boxes.append(bbox)\n",
    "        \n",
    "        logging.info(f\"MathPix - Page {page_number + 1} processed in {elapsed_time:.2f} seconds.\")\n",
    "        return text, bounding_boxes, elapsed_time\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"MathPix API request failed for page {page_number + 1}: {e}\", exc_info=True)\n",
    "        return '', [], 0.0\n",
    "    except Exception as e:\n",
    "        logger.error(f\"MathPix - Exception on page {page_number + 1}: {e}\", exc_info=True)\n",
    "        return '', [], 0.0\n",
    "    \n",
    "def perform_mathpix_ocr(pdf_path, max_workers=MAX_WORKERS):\n",
    "    \"\"\"\n",
    "    Performs OCR on a PDF document using MathPix and evaluates processing speed.\n",
    "\n",
    "    Parameters:\n",
    "    - pdf_path (str): Path to the PDF file.\n",
    "    - max_workers (int): Number of worker processes for parallel OCR.\n",
    "\n",
    "    Returns:\n",
    "    - ocr_text (str): Concatenated OCR text from all pages.\n",
    "    - bounding_boxes_all_pages (list): List of bounding boxes dictionaries for all pages.\n",
    "    - total_time (float): Total time taken for OCR in seconds.\n",
    "    - per_page_times (list): List of processing times per page in seconds.\n",
    "    \"\"\"\n",
    "    ocr_text_pages = []\n",
    "    bounding_boxes_all_pages = []\n",
    "    per_page_times = []\n",
    "    images = convert_pdf_to_images(pdf_path)\n",
    "    num_pages = len(images)\n",
    "    logging.info(f\"Total pages to process with MathPix: {num_pages}\")\n",
    "\n",
    "    if num_pages == 0:\n",
    "        logging.warning(\"No images extracted from PDF.\")\n",
    "        return '', [], 0.0, []\n",
    "\n",
    "    # Start total OCR timing\n",
    "    total_start_time = time.time()\n",
    "\n",
    "    # Use ThreadPoolExecutor for parallel processing\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit all pages to the executor\n",
    "        futures = {executor.submit(ocr_page_mathpix, i, img): i for i, img in enumerate(images)}\n",
    "        \n",
    "        # Iterate over completed futures with a progress bar\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=num_pages, desc=\"Performing MathPix OCR\"):\n",
    "            page_number = futures[future]\n",
    "            try:\n",
    "                text, bounding_boxes, proc_time = future.result()\n",
    "                ocr_text_pages.append(text)\n",
    "                bounding_boxes_all_pages.extend(bounding_boxes)\n",
    "                per_page_times.append(proc_time)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error retrieving MathPix result for page {page_number + 1}: {e}\", exc_info=True)\n",
    "                ocr_text_pages.append('')\n",
    "                per_page_times.append(0.0)\n",
    "    \n",
    "    # End total OCR timing\n",
    "    total_end_time = time.time()\n",
    "    total_time = total_end_time - total_start_time\n",
    "    logging.info(f\"Total MathPix OCR time: {total_time:.2f} seconds.\")\n",
    "\n",
    "    # Concatenate all pages' text\n",
    "    ocr_text = '\\n'.join(ocr_text_pages)\n",
    "\n",
    "    page_results = []\n",
    "    for i, (text, bounding_boxes, proc_time) in enumerate(zip(ocr_text_pages, bounding_boxes_all_pages, per_page_times)):\n",
    "        page_bounding_boxes = [\n",
    "            BoundingBox(\n",
    "                page_number=bbox['page_number'],\n",
    "                x=bbox['x'],\n",
    "                y=bbox['y'],\n",
    "                width=bbox['width'],\n",
    "                height=bbox['height'],\n",
    "                text=bbox['text'],\n",
    "                confidence=bbox['confidence'],\n",
    "                type=bbox['type']\n",
    "            )\n",
    "            for bbox in bounding_boxes if bbox['page_number'] == i+1\n",
    "        ]\n",
    "        page_results.append(OCRPageResult(\n",
    "            page_number=i+1,\n",
    "            text=text,\n",
    "            bounding_boxes=page_bounding_boxes,\n",
    "            processing_time=proc_time\n",
    "        ))\n",
    "\n",
    "    return OCRResult(\n",
    "        ocr_text=ocr_text,\n",
    "        page_results=page_results,\n",
    "        total_time=total_time,\n",
    "        ocr_engine=\"Mathpix\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f8dbd684-262a-4d2a-8583-48f9ebaf6a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_page_google(page_number, image):\n",
    "    \"\"\"\n",
    "    Performs OCR on a single image using Google Cloud Vision, extracts bounding boxes with confidence scores,\n",
    "    and measures processing time.\n",
    "\n",
    "    Parameters:\n",
    "    - page_number (int): The page number.\n",
    "    - image (PIL.Image): The image to perform OCR on.\n",
    "\n",
    "    Returns:\n",
    "    - tuple:\n",
    "        - text (str): The full extracted text.\n",
    "        - bounding_boxes (list): List of dictionaries with 'text', 'bounding_box', and 'confidence'.\n",
    "        - elapsed_time (float): Time taken to process the page in seconds.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize Google Cloud Vision client inside the worker\n",
    "        client = vision.ImageAnnotatorClient()\n",
    "        \n",
    "        # Preprocess image using existing function\n",
    "        preprocessed_image = preprocess_image(image)\n",
    "        \n",
    "        # Convert image to bytes\n",
    "        img_byte_arr = io.BytesIO()\n",
    "        preprocessed_image.save(img_byte_arr, format='PNG')\n",
    "        img_bytes = img_byte_arr.getvalue()\n",
    "        \n",
    "        # Create Image object\n",
    "        vision_image = vision.Image(content=img_bytes)\n",
    "        \n",
    "        # Start timing\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Perform text detection\n",
    "        response = client.text_detection(image=vision_image)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        if response.error.message:\n",
    "            logging.error(f\"Google Vision - Error on page {page_number + 1}: {response.error.message}\")\n",
    "            return '', [], elapsed_time\n",
    "        \n",
    "        texts = response.text_annotations\n",
    "        if texts:\n",
    "            # The first text_annotation is the full text\n",
    "            full_text = texts[0].description\n",
    "            \n",
    "            # Extract bounding boxes and confidence scores for each detected text element (excluding the full text)\n",
    "            bounding_boxes = []\n",
    "            for text in texts[1:]:\n",
    "                bbox = [(vertex.x, vertex.y) for vertex in text.bounding_poly.vertices]\n",
    "                confidence = text.confidence if hasattr(text, 'confidence') else None\n",
    "                bounding_boxes.append({\n",
    "                    'text': text.description,\n",
    "                    'bounding_box': bbox,\n",
    "                    'confidence': confidence\n",
    "                })\n",
    "        else:\n",
    "            full_text = ''\n",
    "            bounding_boxes = []\n",
    "        \n",
    "        logging.info(f\"Google Vision - Page {page_number + 1} processed in {elapsed_time:.2f} seconds.\")\n",
    "        return full_text, bounding_boxes, elapsed_time\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Google Vision - Exception on page {page_number + 1}: {e}\")\n",
    "        return '', [], 0.0\n",
    "\n",
    "# Google Cloud Vision OCR Implementation\n",
    "def perform_google_cloud_vision_ocr(pdf_path, max_workers=MAX_WORKERS):\n",
    "    \"\"\"\n",
    "    Performs OCR on a PDF document using Google Cloud Vision and evaluates processing speed.\n",
    "\n",
    "    Parameters:\n",
    "    - pdf_path (str): Path to the PDF file.\n",
    "    - max_workers (int or None): Number of worker processes for parallel OCR.\n",
    "                                  If None, defaults to the number of CPU cores.\n",
    "\n",
    "    Returns:\n",
    "    - tuple:\n",
    "        - ocr_text (str): Concatenated OCR text from all pages.\n",
    "        - bounding_boxes_pages (list): List of bounding boxes per page.\n",
    "        - total_time (float): Total time taken for OCR in seconds.\n",
    "        - per_page_times (list): List of processing times per page in seconds.\n",
    "    \"\"\"\n",
    "    ocr_text_pages = []\n",
    "    bounding_boxes_pages = []\n",
    "    per_page_times = []\n",
    "    images = convert_pdf_to_images(pdf_path)\n",
    "    num_pages = len(images)\n",
    "    logging.info(f\"Total pages to process with Google Cloud Vision: {num_pages}\")\n",
    "\n",
    "    if num_pages == 0:\n",
    "        logging.warning(\"No images extracted from PDF.\")\n",
    "        return '', [], 0.0, []\n",
    "\n",
    "    # Start total OCR timing\n",
    "    total_start_time = time.time()\n",
    "\n",
    "    # Use ThreadPoolExecutor for parallel processing\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit all pages to the executor\n",
    "        futures = {executor.submit(ocr_page_google, i, img): i for i, img in enumerate(images)}\n",
    "        \n",
    "        # Iterate over completed futures with a progress bar\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=num_pages, desc=\"Performing Google Cloud Vision OCR\"):\n",
    "            page_number = futures[future]\n",
    "            try:\n",
    "                text, bounding_boxes, proc_time = future.result()\n",
    "                ocr_text_pages.append(text)\n",
    "                bounding_boxes_pages.append(bounding_boxes)\n",
    "                per_page_times.append(proc_time)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error retrieving Google Cloud Vision result for page {page_number + 1}: {e}\", exc_info=True)\n",
    "                ocr_text_pages.append('')\n",
    "                bounding_boxes_pages.append([])\n",
    "                per_page_times.append(0.0)\n",
    "\n",
    "    # End total OCR timing\n",
    "    total_end_time = time.time()\n",
    "    total_time = total_end_time - total_start_time\n",
    "    logging.info(f\"Total Google Cloud Vision OCR time: {total_time:.2f} seconds.\")\n",
    "\n",
    "    # Concatenate all pages' text\n",
    "    ocr_text = '\\n'.join(ocr_text_pages)\n",
    "\n",
    "    page_results = []\n",
    "    for i, (text, bounding_boxes, proc_time) in enumerate(zip(ocr_text_pages, bounding_boxes_pages, per_page_times)):\n",
    "        page_bounding_boxes = [\n",
    "            BoundingBox(\n",
    "                page_number=i+1,\n",
    "                x=min(vertex[0] for vertex in bbox['bounding_box']),\n",
    "                y=min(vertex[1] for vertex in bbox['bounding_box']),\n",
    "                width=max(vertex[0] for vertex in bbox['bounding_box']) - min(vertex[0] for vertex in bbox['bounding_box']),\n",
    "                height=max(vertex[1] for vertex in bbox['bounding_box']) - min(vertex[1] for vertex in bbox['bounding_box']),\n",
    "                text=bbox['text'],\n",
    "                confidence=bbox['confidence']\n",
    "            )\n",
    "            for bbox in bounding_boxes\n",
    "        ]\n",
    "        page_results.append(OCRPageResult(\n",
    "            page_number=i+1,\n",
    "            text=text,\n",
    "            bounding_boxes=page_bounding_boxes,\n",
    "            processing_time=proc_time\n",
    "        ))\n",
    "\n",
    "    return OCRResult(\n",
    "        ocr_text=ocr_text,\n",
    "        page_results=page_results,\n",
    "        total_time=total_time,\n",
    "        ocr_engine=\"Google Cloud Vision\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "682b032c-ffda-40f0-ba9e-ab511b0a83a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8367127e-0f14-4599-b4c0-13d6c9e6b428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text: str) -> str:\n",
    "    \"\"\"Normalize text by lowercasing and removing extra whitespace.\"\"\"\n",
    "    return ' '.join(text.lower().split())\n",
    "\n",
    "def character_error_rate(reference: str, hypothesis: str) -> float:\n",
    "    \"\"\"Calculate the Character Error Rate (CER).\"\"\"\n",
    "    return Levenshtein.distance(reference, hypothesis) / len(reference)\n",
    "\n",
    "def word_error_rate(reference: str, hypothesis: str) -> float:\n",
    "    \"\"\"Calculate the Word Error Rate (WER).\"\"\"\n",
    "    ref_words = reference.split()\n",
    "    hyp_words = hypothesis.split()\n",
    "    return Levenshtein.distance(ref_words, hyp_words) / len(ref_words)\n",
    "\n",
    "def fuzzy_string_match(reference: str, hypothesis: str) -> float:\n",
    "    \"\"\"Calculate a fuzzy string match score using fuzzywuzzy.\"\"\"\n",
    "    return fuzz.ratio(reference, hypothesis) / 100.0\n",
    "\n",
    "def confidence_weighted_accuracy(reference: str, hypothesis: str, confidences: List[float]) -> float:\n",
    "    \"\"\"Calculate the Confidence Weighted Accuracy (CWA).\"\"\"\n",
    "    ref_words = reference.split()\n",
    "    hyp_words = hypothesis.split()\n",
    "    \n",
    "    if len(hyp_words) != len(confidences):\n",
    "        raise ValueError(\"Number of words in hypothesis doesn't match number of confidence scores\")\n",
    "    \n",
    "    correct_confidence_sum = sum(conf for ref, hyp, conf in zip(ref_words, hyp_words, confidences) if ref == hyp)\n",
    "    total_confidence_sum = sum(confidences)\n",
    "    \n",
    "    return correct_confidence_sum / total_confidence_sum if total_confidence_sum > 0 else 0.0\n",
    "\n",
    "def evaluate_ocr(ground_truth: AnthropicResult, ocr_result: OCRResult) -> Dict[str, float]:\n",
    "    \"\"\"Evaluate OCR results against ground truth.\"\"\"\n",
    "    gt_text = normalize_text(ground_truth.full_text)\n",
    "    ocr_text = normalize_text(ocr_result.ocr_text)\n",
    "    \n",
    "    evaluation = {\n",
    "        'CER': character_error_rate(gt_text, ocr_text),\n",
    "        'WER': word_error_rate(gt_text, ocr_text),\n",
    "        'Fuzzy_Match': fuzzy_string_match(gt_text, ocr_text),\n",
    "        'Total_Time': ocr_result.total_time,\n",
    "        'Avg_Time_Per_Page': np.mean([page.processing_time for page in ocr_result.page_results]),\n",
    "    }\n",
    "    \n",
    "    # Calculate CWA if confidence scores are available\n",
    "    if hasattr(ocr_result.page_results[0], 'avg_confidence'):\n",
    "        confidences = [page.avg_confidence for page in ocr_result.page_results if page.avg_confidence is not None]\n",
    "        if confidences:\n",
    "            evaluation['CWA'] = confidence_weighted_accuracy(gt_text, ocr_text, confidences)\n",
    "    \n",
    "    return evaluation\n",
    "\n",
    "def evaluate_all_ocrs(ground_truth: AnthropicResult, ocr_results: Dict[str, OCRResult]) -> pd.DataFrame:\n",
    "    \"\"\"Evaluate all OCR results and return a DataFrame with the results.\"\"\"\n",
    "    evaluations = {}\n",
    "    for ocr_name, ocr_result in ocr_results.items():\n",
    "        evaluations[ocr_name] = evaluate_ocr(ground_truth, ocr_result)\n",
    "    \n",
    "    return pd.DataFrame(evaluations).transpose()\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Path to your PDF file\n",
    "        pdf_path = \"bagel_jays.pdf\"\n",
    "\n",
    "        # Assume you have these results from previous processing\n",
    "        # Ground Truth Text\n",
    "        ground_truth_checkpoint = 'ground_truth_checkpoint.pkl'\n",
    "        ground_truth = load_checkpoint(ground_truth_checkpoint)\n",
    "        if ground_truth is None:\n",
    "            ground_truth = get_anthropic_ground_truth(pdf_path)\n",
    "            save_checkpoint(ground_truth, ground_truth_checkpoint)\n",
    "\n",
    "        # Tesseract OCR\n",
    "        tesseract_checkpoint = 'tesseract_checkpoint.pkl'\n",
    "        tesseract_result = load_checkpoint(tesseract_checkpoint)\n",
    "        if tesseract_result is None:\n",
    "            tesseract_result = perform_tesseract_ocr(pdf_path)\n",
    "            save_checkpoint(tesseract_result, tesseract_checkpoint)\n",
    "\n",
    "        # MathPix OCR\n",
    "        mathpix_checkpoint = 'mathpix_checkpoint.pkl'\n",
    "        mathpix_result = load_checkpoint(mathpix_checkpoint)\n",
    "        if mathpix_result is None:\n",
    "            mathpix_result = perform_mathpix_ocr(pdf_path)\n",
    "            save_checkpoint(mathpix_result, mathpix_checkpoint)\n",
    "\n",
    "        # Google Cloud Vision OCR\n",
    "        gcv_checkpoint = 'gcv_checkpoint.pkl'\n",
    "        gcv_result = load_checkpoint(gcv_checkpoint)\n",
    "        if gcv_result is None:\n",
    "            gcv_result = perform_google_cloud_vision_ocr(pdf_path)\n",
    "            save_checkpoint(gcv_result, gcv_checkpoint)\n",
    "        \n",
    "        ocr_results = {\n",
    "            'Tesseract': tesseract_result,\n",
    "            'Mathpix': mathpix_result,\n",
    "            'Google Cloud Vision': gcv_result\n",
    "        }\n",
    "        \n",
    "        # Evaluation\n",
    "        evaluation_checkpoint = 'evaluation_checkpoint.pkl'\n",
    "        evaluation_df = load_checkpoint(evaluation_checkpoint)\n",
    "        if evaluation_df is None:\n",
    "            evaluation_df = evaluate_all_ocrs(ground_truth, ocr_results)\n",
    "            save_checkpoint(evaluation_df, evaluation_checkpoint)\n",
    "        \n",
    "        print(\"OCR Evaluation Results:\")\n",
    "        print(evaluation_df)\n",
    "        \n",
    "        # Visualize results\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        metrics = ['CER', 'WER', 'Fuzzy_Match', 'Total_Time', 'Avg_Time_Per_Page']\n",
    "        \n",
    "        fig, axes = plt.subplots(len(metrics), 1, figsize=(10, 5*len(metrics)))\n",
    "        for i, metric in enumerate(metrics):\n",
    "            evaluation_df[metric].plot(kind='bar', ax=axes[i], title=f'{metric} Comparison')\n",
    "            axes[i].set_ylabel(metric)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Detailed per-page analysis\n",
    "        def per_page_analysis(ground_truth: AnthropicResult, ocr_result: OCRResult) -> pd.DataFrame:\n",
    "            per_page_metrics = []\n",
    "            for gt_page, ocr_page in zip(ground_truth.page_results, ocr_result.page_results):\n",
    "                gt_text = normalize_text(gt_page.text)\n",
    "                ocr_text = normalize_text(ocr_page.text)\n",
    "                metrics = {\n",
    "                    'Page': gt_page.page_number,\n",
    "                    'CER': character_error_rate(gt_text, ocr_text),\n",
    "                    'WER': word_error_rate(gt_text, ocr_text),\n",
    "                    'Fuzzy_Match': fuzzy_string_match(gt_text, ocr_text),\n",
    "                    'Processing_Time': ocr_page.processing_time\n",
    "                }\n",
    "                if hasattr(ocr_page, 'avg_confidence'):\n",
    "                    metrics['Confidence'] = ocr_page.avg_confidence\n",
    "                per_page_metrics.append(metrics)\n",
    "            return pd.DataFrame(per_page_metrics)\n",
    "\n",
    "        # Perform per-page analysis for each OCR method\n",
    "        per_page_checkpoint = 'per_page_checkpoint.pkl'\n",
    "        per_page_results = load_checkpoint(per_page_checkpoint)\n",
    "        if per_page_results is None:\n",
    "            per_page_results = {}\n",
    "            for ocr_name, ocr_result in ocr_results.items():\n",
    "                per_page_results[ocr_name] = per_page_analysis(ground_truth, ocr_result)\n",
    "            save_checkpoint(per_page_results, per_page_checkpoint)\n",
    "\n",
    "        for ocr_name, per_page_df in per_page_results.items():\n",
    "            print(f\"\\nPer-page analysis for {ocr_name}:\")\n",
    "            print(per_page_df)\n",
    "            \n",
    "            # Visualize per-page results\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "            per_page_df.plot(x='Page', y='CER', ax=axes[0, 0], title='CER by Page')\n",
    "            per_page_df.plot(x='Page', y='WER', ax=axes[0, 1], title='WER by Page')\n",
    "            per_page_df.plot(x='Page', y='Fuzzy_Match', ax=axes[1, 0], title='Fuzzy Match by Page')\n",
    "            per_page_df.plot(x='Page', y='Processing_Time', ax=axes[1, 1], title='Processing Time by Page')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during execution: {e}\", exc_info=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
