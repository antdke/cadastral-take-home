{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d214b15d-e8f3-42bc-b690-1aa89db6d705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import pytesseract  # For OCR using Tesseract\n",
    "import time         # For measuring execution time\n",
    "import pdf2image    # For converting PDF pages to images\n",
    "from PIL import Image  # For image processing\n",
    "import requests     # For API calls to Anthropic\n",
    "import difflib      # For text comparison\n",
    "import numpy as np  # For numerical operations\n",
    "import cv2          # For advanced image processing\n",
    "import matplotlib.pyplot as plt  # For visualizations\n",
    "import io           # For handling byte streams\n",
    "import base64       # For encoding/decoding binary data\n",
    "from dotenv import load_dotenv  # For loading environment variables from .env file\n",
    "from tqdm import tqdm  # For progress bars\n",
    "import os           # For interacting with the operating system\n",
    "import logging      # For logging messages\n",
    "import concurrent.futures  # For parallel execution of tasks\n",
    "from requests.adapters import HTTPAdapter  # For configuring HTTP requests\n",
    "from requests.packages.urllib3.util.retry import Retry  # For implementing retry logic in HTTP requests\n",
    "from google.cloud import vision # For the Google Cloud Vision client library\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import Levenshtein  # For efficient edit distance calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdd2e261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MAX_WORKERS = os.cpu_count() or 4 # Adjust workers to the number of CPU cores available of current system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d635e36-72fb-4aab-8448-f49334334e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD ENVIRONMENT VARIABLES\n",
    "load_dotenv()\n",
    "\n",
    "# ANTHROPIC\n",
    "ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')\n",
    "if not ANTHROPIC_API_KEY:\n",
    "    raise ValueError(\"Please set the ANTHROPIC_API_KEY environment variable.\")\n",
    "\n",
    "# MATHPIX\n",
    "MATHPIX_APP_ID = os.getenv('MATHPIX_APP_ID')\n",
    "MATHPIX_APP_KEY = os.getenv('MATHPIX_APP_KEY')\n",
    "\n",
    "if not MATHPIX_APP_ID or not MATHPIX_APP_KEY:\n",
    "    raise ValueError(\"Please set the MATHPIX_APP_ID and MATHPIX_APP_KEY environment variables.\")\n",
    "\n",
    "# GOOGLE CLOUD VISION\n",
    "GOOGLE_APPLICATION_CREDENTIALS = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')\n",
    "if not GOOGLE_APPLICATION_CREDENTIALS:\n",
    "    raise ValueError(\"Please set the GOOGLE_APPLICATION_CREDENTIALS environment variable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8a70f93-383a-4f55-aeaa-64dead1bbc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Setup a session with retry strategy\n",
    "session = requests.Session()\n",
    "retry = Retry(\n",
    "    total=5,\n",
    "    backoff_factor=1,\n",
    "    status_forcelist=[429, 500, 502, 503, 504],\n",
    "    allowed_methods=[\"POST\"]\n",
    ")\n",
    "adapter = HTTPAdapter(max_retries=retry)\n",
    "session.mount(\"https://\", adapter)\n",
    "session.mount(\"http://\", adapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b74002a8-0cef-422d-b4e8-810d134bbcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_base64(image, max_dim=1568):\n",
    "    \"\"\"\n",
    "    Converts a PIL Image to a base64-encoded string after resizing if necessary.\n",
    "\n",
    "    Parameters:\n",
    "    - image (PIL.Image): The image to convert.\n",
    "    - max_dim (int): Maximum dimension (width or height) in pixels.\n",
    "\n",
    "    Returns:\n",
    "    - str: Base64-encoded string of the image.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Resize image if any dimension exceeds max_dim\n",
    "        if max(image.size) > max_dim:\n",
    "            ratio = max_dim / max(image.size)\n",
    "            new_size = (int(image.size[0] * ratio), int(image.size[1] * ratio))\n",
    "            image = image.resize(new_size, Image.ANTIALIAS)\n",
    "        \n",
    "        buffered = io.BytesIO()\n",
    "        image.save(buffered, format=\"PNG\")  # Use PNG for lossless quality\n",
    "        img_bytes = buffered.getvalue()\n",
    "        img_base64 = base64.b64encode(img_bytes).decode('utf-8')\n",
    "        return img_base64\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in image_to_base64: {e}\", exc_info=True)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff9dc0db-9686-4538-b6ec-ce471a7b726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    Preprocess the image to enhance OCR accuracy.\n",
    "\n",
    "    Parameters:\n",
    "    - image (PIL.Image): The image to preprocess.\n",
    "\n",
    "    Returns:\n",
    "    - PIL.Image: The preprocessed image.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert to grayscale\n",
    "        image = image.convert('L')\n",
    "        \n",
    "        # Convert to NumPy array for OpenCV processing\n",
    "        image_np = np.array(image)\n",
    "        \n",
    "        # Apply denoising\n",
    "        image_np = cv2.fastNlMeansDenoising(image_np, h=30)\n",
    "\n",
    "        # Apply adaptive thresholding\n",
    "        image_np = cv2.adaptiveThreshold(image_np, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                        cv2.THRESH_BINARY, 11, 2)\n",
    "        \n",
    "        # Detect and correct skew\n",
    "        coords = np.column_stack(np.where(image_np > 0))\n",
    "        angle = cv2.minAreaRect(coords)[-1]\n",
    "        if angle < -45:\n",
    "            angle = -(90 + angle)\n",
    "        else:\n",
    "            angle = -angle\n",
    "        \n",
    "        (h, w) = image_np.shape\n",
    "        center = (w // 2, h // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        rotated = cv2.warpAffine(image_np, M, (w, h), flags=cv2.INTER_CUBIC, \n",
    "                                borderMode=cv2.BORDER_REPLICATE)\n",
    "        \n",
    "        # Convert back to PIL Image\n",
    "        preprocessed_image = Image.fromarray(image_np)\n",
    "        return preprocessed_image\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in preprocess_image: {e}\", exc_info=True)\n",
    "        return image  # Return original image if preprocessing fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08b04abf-52b0-4ab5-a101-00562d21f24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pdf_to_images(pdf_path, dpi=300):\n",
    "    \"\"\"\n",
    "    Converts a PDF file to a list of PIL Image objects.\n",
    "\n",
    "    Parameters:\n",
    "    - pdf_path (str): Path to the PDF file.\n",
    "    - dpi (int): Resolution for the conversion.\n",
    "\n",
    "    Returns:\n",
    "    - list of PIL.Image: List of images representing each PDF page.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        images = pdf2image.convert_from_path(pdf_path, dpi=dpi)\n",
    "        logger.info(f\"Converted PDF to {len(images)} images.\")\n",
    "        return images\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"PDF file not found: {pdf_path}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to convert PDF to images: {e}\", exc_info=True)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "323a47e0-6be9-4494-8d00-b72d361a9e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_page(page_number, image, session):\n",
    "    \"\"\"\n",
    "    Processes a single PDF page: preprocesses image, sends API request, and retrieves text.\n",
    "\n",
    "    Parameters:\n",
    "    - page_number (int): The page number.\n",
    "    - image (PIL.Image): The image of the page.\n",
    "    - session (requests.Session): The HTTP session for making requests.\n",
    "\n",
    "    Returns:\n",
    "    - str: Extracted text from the page.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Preprocess image\n",
    "        image = preprocess_image(image)\n",
    "        \n",
    "        # Convert image to base64\n",
    "        image_base64 = image_to_base64(image)\n",
    "        \n",
    "        # Prepare the messages payload\n",
    "        messages = [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"source\": {\n",
    "                    \"type\": \"base64\",\n",
    "                    \"media_type\": \"image/png\",  # Ensure the media type matches the image format\n",
    "                    \"data\": image_base64,\n",
    "                },\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Output all the text in this page.\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Prepare the API request payload\n",
    "        payload = {\n",
    "            \"model\": \"claude-3-5-sonnet-20240620\",\n",
    "            \"max_tokens\": 1024,\n",
    "            \"messages\": messages\n",
    "        }\n",
    "        \n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {ANTHROPIC_API_KEY}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        \n",
    "        api_endpoint = \"https://api.anthropic.com/v1/messages\"  # Adjust the endpoint if necessary\n",
    "        \n",
    "        start_time = time.time()\n",
    "        response = session.post(api_endpoint, headers=headers, json=payload)\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        response.raise_for_status()  # Raises an HTTPError for bad responses\n",
    "        \n",
    "        response_json = response.json()\n",
    "        # Assuming the response structure contains the text in 'completion'\n",
    "        text = response_json.get('completion', '')\n",
    "\n",
    "        logger.info(f\"Page {page_number} processed in {elapsed_time:.2f} seconds.\")\n",
    "        return text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"API request failed for page {page_number}: {e}\", exc_info=True)\n",
    "        return ''\n",
    "    except KeyError as e:\n",
    "        logger.error(f\"Unexpected response format for page {page_number}: {e}\", exc_info=True)\n",
    "        return ''\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error processing page {page_number}: {e}\", exc_info=True)\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34f4f08a-c3d5-4734-93d6-c33332574212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ground_truth_text(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts ground truth text from a PDF using the Anthropic Vision API.\n",
    "\n",
    "    Parameters:\n",
    "    - pdf_path (str): Path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "    - str: Concatenated text from all pages of the PDF.\n",
    "    \"\"\"\n",
    "    ground_truth_text_pages = []\n",
    "    images = convert_pdf_to_images(pdf_path)\n",
    "    \n",
    "    if not images:\n",
    "        logging.warning(\"No images to process.\")\n",
    "        return ''\n",
    "    \n",
    "    start_total = time.time()\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        futures = [\n",
    "            executor.submit(process_page, page_number, image, session)\n",
    "            for page_number, image in enumerate(images, start=1)\n",
    "        ]\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc=\"Processing pages\"):\n",
    "            try:\n",
    "                result = future.result()\n",
    "                ground_truth_text_pages.append(result)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing page: {e}\", exc_info=True)\n",
    "    end_total = time.time()\n",
    "    \n",
    "    total_time = end_total - start_total\n",
    "    logging.info(f\"Total time to obtain ground truth: {total_time:.2f} seconds.\")\n",
    "    \n",
    "    ground_truth_text = '\\n'.join(ground_truth_text_pages)\n",
    "    return ground_truth_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4211e2ee-2700-44c0-82e5-4125e9fb24a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_tesseract_ocr(pdf_path, max_workers=MAX_WORKERS):\n",
    "    \"\"\"\n",
    "    Performs OCR on a PDF document using Tesseract and evaluates processing speed.\n",
    "\n",
    "    Parameters:\n",
    "    - pdf_path (str): Path to the PDF file.\n",
    "    - max_workers (int or None): Number of worker processes for parallel OCR.\n",
    "                                 If None, it will default to os.cpu_count().\n",
    "\n",
    "    Returns:\n",
    "    - ocr_text (str): Concatenated OCR text from all pages.\n",
    "    - ocr_data_pages (list): List of OCR data dictionaries with bounding boxes.\n",
    "    - total_time (float): Total time taken for OCR in seconds.\n",
    "    - per_page_times (list): List of processing times per page in seconds.\n",
    "    \"\"\"\n",
    "    ocr_text_pages = []\n",
    "    ocr_data_pages = []\n",
    "    per_page_times = []\n",
    "\n",
    "    # Convert PDF to images using existing function\n",
    "    images = convert_pdf_to_images(pdf_path)\n",
    "    num_pages = len(images)\n",
    "    logging.info(f\"Total pages to process: {num_pages}\")\n",
    "\n",
    "    if num_pages == 0:\n",
    "        logging.warning(\"No images extracted from PDF.\")\n",
    "        return '', [], 0.0, []\n",
    "\n",
    "    # Define a helper function for OCR processing\n",
    "    def ocr_page(page_number, image):\n",
    "        \"\"\"\n",
    "        Performs OCR on a single image and measures processing time.\n",
    "\n",
    "        Parameters:\n",
    "        - page_number (int): The page number.\n",
    "        - image (PIL.Image): The image to perform OCR on.\n",
    "\n",
    "        Returns:\n",
    "        - (text, data, processing_time): Tuple containing OCR text, data, and time taken.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Preprocess image using existing function\n",
    "            preprocessed_image = preprocess_image(image)\n",
    "\n",
    "            # Start timing\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Perform OCR to extract text with configuration\n",
    "            custom_config = r'--oem 3 --psm 6'  # Example configuration\n",
    "            text = pytesseract.image_to_string(preprocessed_image, config=custom_config, lang='eng')\n",
    "\n",
    "            # Perform OCR to extract data with bounding boxes\n",
    "            data = pytesseract.image_to_data(preprocessed_image, output_type=pytesseract.Output.DICT, config=custom_config, lang='eng')\n",
    "\n",
    "            # End timing\n",
    "            end_time = time.time()\n",
    "            processing_time = end_time - start_time\n",
    "\n",
    "            logging.info(f\"Page {page_number + 1} processed in {processing_time:.2f} seconds.\")\n",
    "\n",
    "            return text, data, processing_time\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing page {page_number + 1}: {e}\")\n",
    "            return '', {}, 0.0\n",
    "\n",
    "    # Start total OCR timing\n",
    "    total_start_time = time.time()\n",
    "\n",
    "    # Use ProcessPoolExecutor for parallel processing\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit all pages to the executor\n",
    "        futures = {executor.submit(ocr_page, i, img): i for i, img in enumerate(images)}\n",
    "\n",
    "        # Iterate over completed futures with a progress bar\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=num_pages, desc=\"Performing Tesseract OCR\"):\n",
    "            page_number = futures[future]\n",
    "            try:\n",
    "                text, data, proc_time = future.result()\n",
    "                ocr_text_pages.append(text)\n",
    "                ocr_data_pages.append(data)\n",
    "                per_page_times.append(proc_time)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error retrieving result for page {page_number + 1}: {e}\", exc_info=True)\n",
    "\n",
    "\n",
    "    # End total OCR timing\n",
    "    total_end_time = time.time()\n",
    "    total_time = total_end_time - total_start_time\n",
    "    logging.info(f\"Total OCR time: {total_time:.2f} seconds.\")\n",
    "\n",
    "    # Concatenate all pages' text\n",
    "    ocr_text = '\\n'.join(ocr_text_pages)\n",
    "\n",
    "    return ocr_text, ocr_data_pages, total_time, per_page_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56ecbad6-c771-46f3-a269-23c77d1da4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MathPix OCR Implementation\n",
    "def perform_mathpix_ocr(pdf_path, max_workers=MAX_WORKERS):\n",
    "    \"\"\"\n",
    "    Performs OCR on a PDF document using MathPix and evaluates processing speed.\n",
    "\n",
    "    Parameters:\n",
    "    - pdf_path (str): Path to the PDF file.\n",
    "    - max_workers (int): Number of worker processes for parallel OCR.\n",
    "\n",
    "    Returns:\n",
    "    - ocr_text (str): Concatenated OCR text from all pages.\n",
    "    - total_time (float): Total time taken for OCR in seconds.\n",
    "    - per_page_times (list): List of processing times per page in seconds.\n",
    "    \"\"\"\n",
    "    ocr_text_pages = []\n",
    "    per_page_times = []\n",
    "    images = convert_pdf_to_images(pdf_path)\n",
    "    num_pages = len(images)\n",
    "    logging.info(f\"Total pages to process with MathPix: {num_pages}\")\n",
    "\n",
    "    if num_pages == 0:\n",
    "        logging.warning(\"No images extracted from PDF.\")\n",
    "        return '', 0.0, []\n",
    "\n",
    "    # Define a helper function for OCR processing\n",
    "    def ocr_page_mathpix(page_number, image):\n",
    "        \"\"\"\n",
    "        Performs OCR on a single image using MathPix and measures processing time.\n",
    "\n",
    "        Parameters:\n",
    "        - page_number (int): The page number.\n",
    "        - image (PIL.Image): The image to perform OCR on.\n",
    "\n",
    "        Returns:\n",
    "        - (text, processing_time): Tuple containing OCR text and time taken.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Preprocess image using existing function\n",
    "            preprocessed_image = preprocess_image(image)\n",
    "            \n",
    "            # Convert image to base64\n",
    "            image_base64 = image_to_base64(preprocessed_image)\n",
    "            \n",
    "            # Prepare the JSON payload\n",
    "            payload = {\n",
    "                \"src\": f\"data:image/png;base64,{image_base64}\",\n",
    "                \"formats\": [\"text\"],\n",
    "                \"rm_spaces\": True\n",
    "            }\n",
    "            \n",
    "            headers = {\n",
    "                \"app_id\": MATHPIX_APP_ID,\n",
    "                \"app_key\": MATHPIX_APP_KEY,\n",
    "                \"Content-type\": \"application/json\"\n",
    "            }\n",
    "            \n",
    "            api_endpoint = \"https://api.mathpix.com/v3/text\"\n",
    "            \n",
    "            # Start timing\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Send OCR request to MathPix\n",
    "            response = requests.post(api_endpoint, json=payload, headers=headers)\n",
    "            elapsed_time = time.time() - start_time\n",
    "\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            response_json = response.json()\n",
    "            text = response_json.get('text', '')\n",
    "            logging.info(f\"MathPix - Page {page_number + 1} processed in {elapsed_time:.2f} seconds.\")\n",
    "            return text, elapsed_time\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logger.error(f\"MathPix API request failed for page {page_number + 1}: {e}\", exc_info=True)\n",
    "            return '', 0.0\n",
    "        except Exception as e:\n",
    "            logger.error(f\"MathPix - Exception on page {page_number + 1}: {e}\", exc_info=True)\n",
    "            return '', 0.0\n",
    "\n",
    "    # Start total OCR timing\n",
    "    total_start_time = time.time()\n",
    "\n",
    "    # Use ProcessPoolExecutor for parallel processing\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit all pages to the executor\n",
    "        futures = {executor.submit(ocr_page_mathpix, i, img): i for i, img in enumerate(images)}\n",
    "        \n",
    "        # Iterate over completed futures with a progress bar\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=num_pages, desc=\"Performing MathPix OCR\"):\n",
    "            page_number = futures[future]\n",
    "            try:\n",
    "                text, proc_time = future.result()\n",
    "                ocr_text_pages.append(text)\n",
    "                per_page_times.append(proc_time)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error retrieving MathPix result for page {page_number + 1}: {e}\", exc_info=True)\n",
    "                ocr_text_pages.append('')\n",
    "                per_page_times.append(0.0)\n",
    "\n",
    "\n",
    "    # End total OCR timing\n",
    "    total_end_time = time.time()\n",
    "    total_time = total_end_time - total_start_time\n",
    "    logging.info(f\"Total MathPix OCR time: {total_time:.2f} seconds.\")\n",
    "\n",
    "    # Concatenate all pages' text\n",
    "    ocr_text = '\\n'.join(ocr_text_pages)\n",
    "\n",
    "    return ocr_text, total_time, per_page_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8dbd684-262a-4d2a-8583-48f9ebaf6a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Cloud Vision OCR Implementation\n",
    "def perform_google_cloud_vision_ocr(pdf_path, max_workers=MAX_WORKERS):\n",
    "    \"\"\"\n",
    "    Performs OCR on a PDF document using Google Cloud Vision and evaluates processing speed.\n",
    "\n",
    "    Parameters:\n",
    "    - pdf_path (str): Path to the PDF file.\n",
    "    - max_workers (int): Number of worker processes for parallel OCR.\n",
    "\n",
    "    Returns:\n",
    "    - ocr_text (str): Concatenated OCR text from all pages.\n",
    "    - total_time (float): Total time taken for OCR in seconds.\n",
    "    - per_page_times (list): List of processing times per page in seconds.\n",
    "    \"\"\"\n",
    "    ocr_text_pages = []\n",
    "    per_page_times = []\n",
    "    images = convert_pdf_to_images(pdf_path)\n",
    "    num_pages = len(images)\n",
    "    logging.info(f\"Total pages to process with Google Cloud Vision: {num_pages}\")\n",
    "\n",
    "    if num_pages == 0:\n",
    "        logging.warning(\"No images extracted from PDF.\")\n",
    "        return '', 0.0, []\n",
    "\n",
    "    # Define a helper function for OCR processing\n",
    "    def ocr_page_google(page_number, image):\n",
    "        \"\"\"\n",
    "        Performs OCR on a single image using Google Cloud Vision and measures processing time.\n",
    "\n",
    "        Parameters:\n",
    "        - page_number (int): The page number.\n",
    "        - image (PIL.Image): The image to perform OCR on.\n",
    "\n",
    "        Returns:\n",
    "        - (text, processing_time): Tuple containing OCR text and time taken.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Initialize Google Cloud Vision client inside the worker\n",
    "            client = vision.ImageAnnotatorClient()\n",
    "            \n",
    "            # Preprocess image using existing function\n",
    "            preprocessed_image = preprocess_image(image)\n",
    "            \n",
    "            # Convert image to bytes\n",
    "            img_byte_arr = io.BytesIO()\n",
    "            preprocessed_image.save(img_byte_arr, format='PNG')\n",
    "            img_bytes = img_byte_arr.getvalue()\n",
    "            \n",
    "            # Create Image object\n",
    "            vision_image = vision.Image(content=img_bytes)\n",
    "            \n",
    "            # Start timing\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Perform text detection\n",
    "            response = client.text_detection(image=vision_image)\n",
    "            elapsed_time = time.time() - start_time\n",
    "            \n",
    "            if response.error.message:\n",
    "                logging.error(f\"Google Vision - Error on page {page_number + 1}: {response.error.message}\")\n",
    "                return '', elapsed_time\n",
    "            \n",
    "            texts = response.text_annotations\n",
    "            if texts:\n",
    "                # The first text_annotation is the full text\n",
    "                text = texts[0].description\n",
    "            else:\n",
    "                text = ''\n",
    "            \n",
    "            logging.info(f\"Google Vision - Page {page_number + 1} processed in {elapsed_time:.2f} seconds.\")\n",
    "            return text, elapsed_time\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Google Vision - Exception on page {page_number + 1}: {e}\")\n",
    "            return '', 0.0\n",
    "\n",
    "    # Start total OCR timing\n",
    "    total_start_time = time.time()\n",
    "\n",
    "    # Use ProcessPoolExecutor for parallel processing\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit all pages to the executor\n",
    "        futures = {executor.submit(ocr_page_google, i, img): i for i, img in enumerate(images)}\n",
    "        \n",
    "        # Iterate over completed futures with a progress bar\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=num_pages, desc=\"Performing Google Cloud Vision OCR\"):\n",
    "            page_number = futures[future]\n",
    "            try:\n",
    "                text, proc_time = future.result()\n",
    "                ocr_text_pages.append(text)\n",
    "                per_page_times.append(proc_time)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error retrieving Google Cloud Vision result for page {page_number + 1}: {e}\", exc_info=True)\n",
    "                ocr_text_pages.append('')\n",
    "                per_page_times.append(0.0)\n",
    "\n",
    "    # End total OCR timing\n",
    "    total_end_time = time.time()\n",
    "    total_time = total_end_time - total_start_time\n",
    "    logging.info(f\"Total Google Cloud Vision OCR time: {total_time:.2f} seconds.\")\n",
    "\n",
    "    # Concatenate all pages' text\n",
    "    ocr_text = '\\n'.join(ocr_text_pages)\n",
    "\n",
    "    return ocr_text, total_time, per_page_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "682b032c-ffda-40f0-ba9e-ab511b0a83a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f54a941-ed15-4dd9-9135-eb8f6c93c197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-12 23:12:17,878 - ERROR - Failed to convert PDF to images: Unable to get page count. Is poppler installed and in PATH?\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/anthonydike/code/cadastral-take-home/venv/lib/python3.11/site-packages/pdf2image/pdf2image.py\", line 581, in pdfinfo_from_path\n",
      "    proc = Popen(command, env=env, stdout=PIPE, stderr=PIPE)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/subprocess.py\", line 1955, in _execute_child\n",
      "    raise child_exception_type(errno_num, err_msg, err_filename)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'pdfinfo'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/41/t_bbv8td21774jtt253zzrnh0000gn/T/ipykernel_3769/1279282602.py\", line 13, in convert_pdf_to_images\n",
      "    images = pdf2image.convert_from_path(pdf_path, dpi=dpi)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/anthonydike/code/cadastral-take-home/venv/lib/python3.11/site-packages/pdf2image/pdf2image.py\", line 127, in convert_from_path\n",
      "    page_count = pdfinfo_from_path(\n",
      "                 ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/anthonydike/code/cadastral-take-home/venv/lib/python3.11/site-packages/pdf2image/pdf2image.py\", line 607, in pdfinfo_from_path\n",
      "    raise PDFInfoNotInstalledError(\n",
      "pdf2image.exceptions.PDFInfoNotInstalledError: Unable to get page count. Is poppler installed and in PATH?\n",
      "2024-09-12 23:12:17,882 - WARNING - No images to process.\n",
      "2024-09-12 23:12:17,887 - ERROR - Failed to convert PDF to images: Unable to get page count. Is poppler installed and in PATH?\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/anthonydike/code/cadastral-take-home/venv/lib/python3.11/site-packages/pdf2image/pdf2image.py\", line 581, in pdfinfo_from_path\n",
      "    proc = Popen(command, env=env, stdout=PIPE, stderr=PIPE)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/subprocess.py\", line 1955, in _execute_child\n",
      "    raise child_exception_type(errno_num, err_msg, err_filename)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'pdfinfo'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/41/t_bbv8td21774jtt253zzrnh0000gn/T/ipykernel_3769/1279282602.py\", line 13, in convert_pdf_to_images\n",
      "    images = pdf2image.convert_from_path(pdf_path, dpi=dpi)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/anthonydike/code/cadastral-take-home/venv/lib/python3.11/site-packages/pdf2image/pdf2image.py\", line 127, in convert_from_path\n",
      "    page_count = pdfinfo_from_path(\n",
      "                 ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/anthonydike/code/cadastral-take-home/venv/lib/python3.11/site-packages/pdf2image/pdf2image.py\", line 607, in pdfinfo_from_path\n",
      "    raise PDFInfoNotInstalledError(\n",
      "pdf2image.exceptions.PDFInfoNotInstalledError: Unable to get page count. Is poppler installed and in PATH?\n",
      "2024-09-12 23:12:17,888 - INFO - Total pages to process: 0\n",
      "2024-09-12 23:12:17,888 - WARNING - No images extracted from PDF.\n",
      "2024-09-12 23:12:17,889 - INFO - Evaluation Results for Tesseract:\n",
      "2024-09-12 23:12:17,889 - INFO - CER: 0.00%\n",
      "2024-09-12 23:12:17,890 - INFO - WER: 0.00%\n",
      "2024-09-12 23:12:17,890 - INFO - Confidence-Weighted Accuracy: 0.00%\n",
      "2024-09-12 23:12:17,895 - ERROR - Failed to convert PDF to images: Unable to get page count. Is poppler installed and in PATH?\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/anthonydike/code/cadastral-take-home/venv/lib/python3.11/site-packages/pdf2image/pdf2image.py\", line 581, in pdfinfo_from_path\n",
      "    proc = Popen(command, env=env, stdout=PIPE, stderr=PIPE)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/subprocess.py\", line 1955, in _execute_child\n",
      "    raise child_exception_type(errno_num, err_msg, err_filename)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'pdfinfo'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/41/t_bbv8td21774jtt253zzrnh0000gn/T/ipykernel_3769/1279282602.py\", line 13, in convert_pdf_to_images\n",
      "    images = pdf2image.convert_from_path(pdf_path, dpi=dpi)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/anthonydike/code/cadastral-take-home/venv/lib/python3.11/site-packages/pdf2image/pdf2image.py\", line 127, in convert_from_path\n",
      "    page_count = pdfinfo_from_path(\n",
      "                 ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/anthonydike/code/cadastral-take-home/venv/lib/python3.11/site-packages/pdf2image/pdf2image.py\", line 607, in pdfinfo_from_path\n",
      "    raise PDFInfoNotInstalledError(\n",
      "pdf2image.exceptions.PDFInfoNotInstalledError: Unable to get page count. Is poppler installed and in PATH?\n",
      "2024-09-12 23:12:17,897 - INFO - Total pages to process with MathPix: 0\n",
      "2024-09-12 23:12:17,897 - WARNING - No images extracted from PDF.\n",
      "2024-09-12 23:12:17,898 - INFO - Evaluation Results for MathPix:\n",
      "2024-09-12 23:12:17,898 - INFO - CER: 0.00%\n",
      "2024-09-12 23:12:17,898 - INFO - WER: 0.00%\n",
      "2024-09-12 23:12:17,898 - INFO - Confidence-Weighted Accuracy: N/A\n",
      "2024-09-12 23:12:17,903 - ERROR - Failed to convert PDF to images: Unable to get page count. Is poppler installed and in PATH?\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/anthonydike/code/cadastral-take-home/venv/lib/python3.11/site-packages/pdf2image/pdf2image.py\", line 581, in pdfinfo_from_path\n",
      "    proc = Popen(command, env=env, stdout=PIPE, stderr=PIPE)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/subprocess.py\", line 1955, in _execute_child\n",
      "    raise child_exception_type(errno_num, err_msg, err_filename)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'pdfinfo'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/41/t_bbv8td21774jtt253zzrnh0000gn/T/ipykernel_3769/1279282602.py\", line 13, in convert_pdf_to_images\n",
      "    images = pdf2image.convert_from_path(pdf_path, dpi=dpi)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/anthonydike/code/cadastral-take-home/venv/lib/python3.11/site-packages/pdf2image/pdf2image.py\", line 127, in convert_from_path\n",
      "    page_count = pdfinfo_from_path(\n",
      "                 ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/anthonydike/code/cadastral-take-home/venv/lib/python3.11/site-packages/pdf2image/pdf2image.py\", line 607, in pdfinfo_from_path\n",
      "    raise PDFInfoNotInstalledError(\n",
      "pdf2image.exceptions.PDFInfoNotInstalledError: Unable to get page count. Is poppler installed and in PATH?\n",
      "2024-09-12 23:12:17,905 - INFO - Total pages to process with Google Cloud Vision: 0\n",
      "2024-09-12 23:12:17,905 - WARNING - No images extracted from PDF.\n",
      "2024-09-12 23:12:17,905 - INFO - Evaluation Results for Google Cloud Vision:\n",
      "2024-09-12 23:12:17,905 - INFO - CER: 0.00%\n",
      "2024-09-12 23:12:17,906 - INFO - WER: 0.00%\n",
      "2024-09-12 23:12:17,906 - INFO - Confidence-Weighted Accuracy: N/A\n",
      "2024-09-12 23:12:17,907 - INFO - \n",
      "Evaluation Summary:\n",
      "2024-09-12 23:12:17,910 - INFO -                      CER  WER  CWA  Total Time (s)\n",
      "Tesseract            0.0  0.0  0.0             0.0\n",
      "MathPix              0.0  0.0  NaN             0.0\n",
      "Google Cloud Vision  0.0  0.0  NaN             0.0\n"
     ]
    }
   ],
   "source": [
    "# Text Normalization Function\n",
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    Normalizes text for fair comparison:\n",
    "    - Converts to lowercase\n",
    "    - Removes punctuation\n",
    "    - Removes extra whitespaces\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        # Remove punctuation\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        # Remove extra whitespaces\n",
    "        text = ' '.join(text.split())\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in normalize_text: {e}\", exc_info=True)\n",
    "        return text  # Return original text if normalization fails\n",
    "\n",
    "# Tokenization Function\n",
    "def tokenize_text(text):\n",
    "    \"\"\"\n",
    "    Tokenizes text into words using regex.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use regex to find word boundaries\n",
    "        tokens = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "        return tokens\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in tokenize_text: {e}\", exc_info=True)\n",
    "        return []\n",
    "\n",
    "# Calculate Character Error Rate (CER)\n",
    "def calculate_cer(ground_truth_text, ocr_text):\n",
    "    \"\"\"\n",
    "    Calculates the Character Error Rate (CER) between ground truth text and OCR text.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Normalize texts\n",
    "        gt_text = normalize_text(ground_truth_text)\n",
    "        ocr_text = normalize_text(ocr_text)\n",
    "        \n",
    "        # Compute Levenshtein distance\n",
    "        distance = Levenshtein.distance(gt_text, ocr_text)\n",
    "        \n",
    "        # Calculate CER\n",
    "        cer = (distance / max(len(gt_text), 1)) * 100  # Avoid division by zero\n",
    "        return cer\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in calculate_cer: {e}\", exc_info=True)\n",
    "        return None\n",
    "\n",
    "# Calculate Word Error Rate (WER)\n",
    "def calculate_wer(ground_truth_text, ocr_text):\n",
    "    \"\"\"\n",
    "    Calculates the Word Error Rate (WER) between ground truth text and OCR text.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Tokenize texts into words\n",
    "        gt_words = tokenize_text(ground_truth_text)\n",
    "        ocr_words = tokenize_text(ocr_text)\n",
    "        \n",
    "        # Use Levenshtein distance on word sequences\n",
    "        distance = Levenshtein.distance(' '.join(gt_words), ' '.join(ocr_words))\n",
    "        \n",
    "        # Calculate WER\n",
    "        wer = (distance / max(len(' '.join(gt_words)), 1)) * 100  # Avoid division by zero\n",
    "        return wer\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in calculate_wer: {e}\", exc_info=True)\n",
    "        return None\n",
    "\n",
    "# Extract OCR Words and Confidences\n",
    "def extract_ocr_words_and_confidences(ocr_data_pages):\n",
    "    \"\"\"\n",
    "    Extracts words and their confidence scores from ocr_data_pages.\n",
    "    Returns a list of (word, confidence) tuples.\n",
    "    \"\"\"\n",
    "    ocr_words_confidences = []\n",
    "    try:\n",
    "        for data in ocr_data_pages:\n",
    "            num_words = len(data['text'])\n",
    "            for i in range(num_words):\n",
    "                word = data['text'][i]\n",
    "                conf = int(data['conf'][i])\n",
    "                if conf != -1 and word.strip() != '':\n",
    "                    ocr_words_confidences.append((word.strip(), conf))\n",
    "        return ocr_words_confidences\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in extract_ocr_words_and_confidences: {e}\", exc_info=True)\n",
    "        return ocr_words_confidences\n",
    "\n",
    "# Calculate Confidence-Weighted Accuracy (CWA)\n",
    "def calculate_confidence_weighted_accuracy(gt_words, ocr_words_confidences):\n",
    "    \"\"\"\n",
    "    Calculates confidence-weighted accuracy.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        total_confidence = 0\n",
    "        matched_confidence = 0\n",
    "        ocr_words = [word_conf[0] for word_conf in ocr_words_confidences]\n",
    "        ocr_confidences = [word_conf[1] for word_conf in ocr_words_confidences]\n",
    "        \n",
    "        # For simplicity, align words based on order\n",
    "        min_len = min(len(gt_words), len(ocr_words))\n",
    "        for i in range(min_len):\n",
    "            gt_word = gt_words[i]\n",
    "            ocr_word = ocr_words[i]\n",
    "            conf = ocr_confidences[i]\n",
    "            total_confidence += conf\n",
    "            if gt_word == ocr_word:\n",
    "                matched_confidence += conf\n",
    "        \n",
    "        # Handle remaining words if any (optional)\n",
    "        # Avoid division by zero\n",
    "        if total_confidence == 0:\n",
    "            return 0.0\n",
    "        cwa = (matched_confidence / total_confidence) * 100\n",
    "        return cwa\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in calculate_confidence_weighted_accuracy: {e}\", exc_info=True)\n",
    "        return None\n",
    "\n",
    "def perform_error_analysis(gt_text, ocr_text):\n",
    "    \"\"\"\n",
    "    Performs error analysis between ground truth and OCR text.\n",
    "    \n",
    "    Returns:\n",
    "    - error_details (dict): Counts of substitutions, insertions, deletions.\n",
    "    \"\"\"\n",
    "    import difflib\n",
    "    matcher = difflib.SequenceMatcher(None, gt_text, ocr_text)\n",
    "    error_details = {'substitutions': 0, 'insertions': 0, 'deletions': 0}\n",
    "    \n",
    "    for opcode, a0, a1, b0, b1 in matcher.get_opcodes():\n",
    "        if opcode == 'replace':\n",
    "            error_details['substitutions'] += max(a1 - a0, b1 - b0)\n",
    "        elif opcode == 'insert':\n",
    "            error_details['insertions'] += b1 - b0\n",
    "        elif opcode == 'delete':\n",
    "            error_details['deletions'] += a1 - a0\n",
    "    \n",
    "    return error_details\n",
    "\n",
    "def evaluate_ocr_results_per_page(ground_truth_pages, ocr_pages, ocr_data_pages=None):\n",
    "    \"\"\"\n",
    "    Evaluates OCR results per page using various metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    - ground_truth_pages (list of str): Ground truth text for each page.\n",
    "    - ocr_pages (list of str): OCR output text for each page.\n",
    "    - ocr_data_pages (list, optional): OCR data with bounding boxes per page.\n",
    "    \n",
    "    Returns:\n",
    "    - results_per_page (list of dict): Evaluation metrics per page.\n",
    "    \"\"\"\n",
    "    results_per_page = []\n",
    "    for i, (gt_text, ocr_text) in enumerate(zip(ground_truth_pages, ocr_pages)):\n",
    "        page_number = i + 1\n",
    "        method_name = f\"Page {page_number}\"\n",
    "        ocr_data_page = ocr_data_pages[i] if ocr_data_pages else None\n",
    "        \n",
    "        # Evaluate metrics\n",
    "        metrics = evaluate_ocr_results(gt_text, ocr_text, [ocr_data_page] if ocr_data_page else None, method_name)\n",
    "        results_per_page.append(metrics)\n",
    "    \n",
    "    return results_per_page\n",
    "\n",
    "# Evaluate OCR Results\n",
    "def evaluate_ocr_results(ground_truth_text, ocr_text, ocr_data_pages, method_name):\n",
    "    \"\"\"\n",
    "    Evaluates OCR results using various metrics.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Normalize texts\n",
    "        normalized_gt_text = normalize_text(ground_truth_text)\n",
    "        normalized_ocr_text = normalize_text(ocr_text)\n",
    "\n",
    "        # Compute CER\n",
    "        cer = calculate_cer(normalized_gt_text, normalized_ocr_text)\n",
    "\n",
    "        # Compute WER\n",
    "        wer = calculate_wer(normalized_gt_text, normalized_ocr_text)\n",
    "\n",
    "        # Tokenize texts into words\n",
    "        gt_words = tokenize_text(ground_truth_text)\n",
    "        ocr_words = tokenize_text(ocr_text)\n",
    "\n",
    "        # Optionally compute confidence-weighted accuracy if ocr_data_pages is available\n",
    "        if ocr_data_pages is not None:\n",
    "            ocr_words_confidences = extract_ocr_words_and_confidences(ocr_data_pages)\n",
    "            cwa = calculate_confidence_weighted_accuracy(gt_words, ocr_words_confidences)\n",
    "        else:\n",
    "            cwa = None\n",
    "\n",
    "        # Log the results\n",
    "        logger.info(f\"Evaluation Results for {method_name}:\")\n",
    "        logger.info(f\"CER: {cer:.2f}%\")\n",
    "        logger.info(f\"WER: {wer:.2f}%\")\n",
    "        if cwa is not None:\n",
    "            logger.info(f\"Confidence-Weighted Accuracy: {cwa:.2f}%\")\n",
    "        else:\n",
    "            logger.info(\"Confidence-Weighted Accuracy: N/A\")\n",
    "\n",
    "        # Perform error analysis\n",
    "        error_details = perform_error_analysis(normalized_gt_text, normalized_ocr_text)\n",
    "\n",
    "        # Return results as a dictionary\n",
    "        return {'CER': cer, 'WER': wer, 'CWA': cwa, 'Errors': error_details}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in evaluate_ocr_results for {method_name}: {e}\", exc_info=True)\n",
    "        return {'CER': None, 'WER': None, 'CWA': None, 'Errors': None}\n",
    "\n",
    "# Present Evaluation Results\n",
    "def present_evaluation_results(results_dict):\n",
    "    \"\"\"\n",
    "    Presents evaluation results in a table.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.DataFrame(results_dict).transpose()\n",
    "        logger.info(\"\\nEvaluation Summary:\")\n",
    "        logger.info(df.to_string())\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in present_evaluation_results: {e}\", exc_info=True)\n",
    "\n",
    "def visualize_ocr_errors(image, ocr_data_page, gt_words_page):\n",
    "    \"\"\"\n",
    "    Visualizes OCR results by overlaying bounding boxes on the image.\n",
    "    \n",
    "    Parameters:\n",
    "    - image (PIL.Image): Original image of the page.\n",
    "    - ocr_data_page (dict): OCR data with bounding boxes.\n",
    "    - gt_words_page (list of str): Ground truth words for the page.\n",
    "    \"\"\"\n",
    "    import matplotlib.patches as patches\n",
    "\n",
    "    # Convert image to displayable format\n",
    "    image_np = np.array(image)\n",
    "    fig, ax = plt.subplots(1, figsize=(15, 20))\n",
    "    ax.imshow(image_np)\n",
    "    \n",
    "    num_words = len(ocr_data_page['text'])\n",
    "    gt_index = 0\n",
    "    gt_words = tokenize_text(' '.join(gt_words_page))\n",
    "    \n",
    "    for i in range(num_words):\n",
    "        word = ocr_data_page['text'][i]\n",
    "        conf = int(ocr_data_page['conf'][i])\n",
    "        x, y, w, h = (ocr_data_page['left'][i], ocr_data_page['top'][i],\n",
    "                      ocr_data_page['width'][i], ocr_data_page['height'][i])\n",
    "        \n",
    "        if word.strip() == '':\n",
    "            continue\n",
    "        \n",
    "        # Determine if the word matches the ground truth\n",
    "        gt_word = gt_words[gt_index] if gt_index < len(gt_words) else ''\n",
    "        match = word.strip().lower() == gt_word.strip().lower()\n",
    "        \n",
    "        # Choose color based on match\n",
    "        color = 'green' if match else 'red'\n",
    "        \n",
    "        # Create a Rectangle patch\n",
    "        rect = patches.Rectangle((x, y), w, h, linewidth=1, edgecolor=color, facecolor='none')\n",
    "        \n",
    "        # Add the patch to the Axes\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Optionally, annotate with the word\n",
    "        ax.text(x, y - 5, word, color=color, fontsize=8, weight='bold')\n",
    "        \n",
    "        gt_index += 1  # Move to next ground truth word\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Main Execution Flow\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Path to your PDF file\n",
    "        pdf_path = \"bagel_jays.pdf\"\n",
    "\n",
    "        # Get ground truth text\n",
    "        ground_truth_text = get_ground_truth_text(pdf_path)\n",
    "\n",
    "        # Perform Tesseract OCR\n",
    "        ocr_text_tesseract, ocr_data_pages_tesseract, tesseract_total_time, tesseract_per_page_times = perform_tesseract_ocr(pdf_path)\n",
    "\n",
    "        # Evaluate Tesseract OCR results\n",
    "        tesseract_results = evaluate_ocr_results(ground_truth_text, ocr_text_tesseract, ocr_data_pages_tesseract, \"Tesseract\")\n",
    "\n",
    "        # Perform MathPix OCR\n",
    "        ocr_text_mathpix, mathpix_total_time, mathpix_per_page_times = perform_mathpix_ocr(pdf_path)\n",
    "\n",
    "        # Evaluate MathPix OCR results\n",
    "        mathpix_results = evaluate_ocr_results(ground_truth_text, ocr_text_mathpix, None, \"MathPix\")\n",
    "\n",
    "        # Perform Google Cloud Vision OCR\n",
    "        ocr_text_gcv, gcv_total_time, gcv_per_page_times = perform_google_cloud_vision_ocr(pdf_path)\n",
    "\n",
    "        # Evaluate Google Cloud Vision OCR results\n",
    "        gcv_results = evaluate_ocr_results(ground_truth_text, ocr_text_gcv, None, \"Google Cloud Vision\")\n",
    "\n",
    "        # Collect all results\n",
    "        evaluation_results = {\n",
    "            'Tesseract': {\n",
    "                'CER': tesseract_results['CER'],\n",
    "                'WER': tesseract_results['WER'],\n",
    "                'CWA': tesseract_results['CWA'],\n",
    "                'Total Time (s)': tesseract_total_time\n",
    "            },\n",
    "            'MathPix': {\n",
    "                'CER': mathpix_results['CER'],\n",
    "                'WER': mathpix_results['WER'],\n",
    "                'CWA': None,  # Not applicable\n",
    "                'Total Time (s)': mathpix_total_time\n",
    "            },\n",
    "            'Google Cloud Vision': {\n",
    "                'CER': gcv_results['CER'],\n",
    "                'WER': gcv_results['WER'],\n",
    "                'CWA': None,  # Not applicable\n",
    "                'Total Time (s)': gcv_total_time\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Present the evaluation results\n",
    "        present_evaluation_results(evaluation_results)\n",
    "\n",
    "        for page_number, (image, ocr_data_page, gt_text_page) in enumerate(zip(images, ocr_data_pages_tesseract, ground_truth_pages)):\n",
    "            gt_words_page = tokenize_text(gt_text_page)\n",
    "            visualize_ocr_errors(image, ocr_data_page, gt_words_page)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during execution: {e}\", exc_info=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
